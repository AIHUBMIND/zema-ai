# Zema AI Personal Assistant - Cursor AI Rules

## Project Overview
- This is Zema AI Personal Assistant - privacy-first voice assistant
- Runs on mini PC (BOSGAME P3 Lite) with Ubuntu 22.04
- Uses Ollama for local LLM inference (Llama 13B) - 100% offline
- Built with Python 3.11+, FastAPI, async/await
- GitHub Repository: https://github.com/AIHUBMIND/zema-ai.git

## Code Style
- Follow PEP 8 Python style guide
- Use type hints for all functions
- Prefer async/await over sync code
- Use Pydantic for data validation
- Use docstrings for all public functions and classes
- **NO EMOJIS IN CODE**: Avoid using emojis (⚠️, ✅, ❌, ℹ️, etc.) in code strings, print statements, or output messages. Use plain text labels like "[OK]", "WARNING", "ERROR", "INFO" instead. Emojis cause encoding issues on Windows and make code more complicated.
- Use ASCII-compatible characters only in code output

## Architecture Principles
- Smart Hybrid Mode: Automatically detects Internet connectivity and switches between online services (preferred) and local LLM (fallback)
- Offline-first: All core features work without internet using local LLM as fallback
- Privacy-first: All data stored locally when offline; online data usage is configurable
- Modular: Each module has single responsibility
- Async-first: Use async/await for I/O operations

## Project Structure
- `src/core/` - Core orchestrator, state management
- `src/config/` - Configuration management (Pydantic)
- `src/voice/` - Voice I/O, wake word, STT, TTS
- `src/vision/` - Camera, vision processing
- `src/ai/` - LLM client, context management
- `src/tools/` - Personal assistant tools
- `src/api/` - FastAPI server, routes
- `src/utils/` - Utilities, logging, helpers

## Best Practices
- Use structured logging with structlog
- Handle errors gracefully with proper exception handling
- Validate all inputs with Pydantic models
- Keep functions small and focused
- Write tests for critical functionality
- Document public APIs

## UI-First Configuration (CRITICAL)
**CRITICAL RULE:** All configuration and settings MUST be accessible through the Settings Dashboard UI.

### Configuration Management Rules:
1. **Every setting that can be configured via command line MUST also be available in Settings Dashboard**
   - If you add a new configuration option to `.env` or `settings.py`, you MUST add it to the Settings Dashboard
   - If you create a command-line tool or script, add equivalent UI controls to the dashboard
   - The goal is to control EVERY aspect of the application through UI/UX

2. **Settings Dashboard Requirements:**
   - All user-facing settings must be in `/api/config/user-facing` endpoint
   - Settings must be organized into logical tabs (General, Voice & Audio, Camera & Vision, AI & Intelligence, Features, API Keys)
   - Settings must have clear labels, descriptions, and appropriate input types (dropdown, slider, checkbox, text input)
   - Settings must validate input and provide clear error messages
   - Settings must save and persist automatically

3. **New Feature Configuration:**
   - When adding new features that require configuration:
     - Add settings to `src/config/settings.py` (Settings class)
     - Add to `USER_FACING_SETTINGS` in `src/api/routes/config.py`
     - Add UI controls to Settings Dashboard (`src/api/static/index.html`)
     - Add JavaScript handlers in `src/api/static/js/app.js`
     - Update `.env.example` with new variables

4. **Command-Line Tools:**
   - Command-line tools are acceptable for:
     - Hardware verification scripts
     - Development/debugging tools
     - One-time setup scripts
   - However, any configuration they modify MUST also be accessible via Settings Dashboard
   - Prefer UI over command-line for ongoing maintenance and updates

5. **Maintenance Through UI:**
   - System updates, model downloads, hardware configuration should be manageable through UI
   - Add "System Management" or "Advanced" section to Settings Dashboard if needed
   - Keep command-line tools as fallback only, not primary method

### Examples:
- ✅ **GOOD**: Wake word sensitivity setting → Added to Settings Dashboard Voice & Audio tab with slider
- ✅ **GOOD**: Ollama model selection → Added to Settings Dashboard AI & Intelligence tab with dropdown
- ❌ **BAD**: Adding new setting only to `.env` without adding to Settings Dashboard
- ❌ **BAD**: Requiring command-line tools for routine configuration changes

### Why This Matters:
- **Easy Maintenance**: Non-technical users can configure the system
- **Remote Management**: Can configure system through web dashboard
- **Consistency**: All configuration in one place (Settings Dashboard)
- **User Experience**: Better UX than editing config files manually
- **Future-Proof**: Easy to add new features without breaking existing configuration flow

## Dependencies
- FastAPI for web API
- Pydantic for validation
- SQLAlchemy for database
- PyAudio for audio I/O
- OpenCV for vision processing
- Faster Whisper for STT
- Ollama for LLM inference (local)

## Git Workflow & Auto-Commit (CRITICAL)

### After Completing Every Task
**CRITICAL RULE:** After completing ANY task, feature, or change, you MUST:
1. Run the auto-commit script: `python scripts/auto_commit.py "task description"`
2. Use descriptive task descriptions (e.g., "Added configuration system", "Implemented voice module")
3. The script will automatically:
   - Stage all changes (`git add .`)
   - Create commit with formatted message (`feat: task description - timestamp`)
   - Push to GitHub (`origin/main` → https://github.com/AIHUBMIND/zema-ai.git)

### Auto-Commit Command Format
```bash
python scripts/auto_commit.py "brief task description"
```

Examples:
- `python scripts/auto_commit.py "Added configuration system"`
- `python scripts/auto_commit.py "Implemented voice module"`
- `python scripts/auto_commit.py "Fixed bug in API endpoint"`
- `python scripts/auto_commit.py "Updated documentation"`

### Commit Message Format
The script automatically formats messages as:
- `feat: task description - YYYY-MM-DD HH:MM:SS`

### Task Completion Checklist
When finishing any task, ALWAYS:
- [ ] Code is complete and tested
- [ ] Follows project style guidelines
- [ ] Documentation updated if needed
- [ ] **Run auto-commit:** `python scripts/auto_commit.py "task description"`
- [ ] Verify push to GitHub was successful

### Manual Commit (if auto-commit fails)
If the auto-commit script fails, use manual commands:
```bash
git add .
git commit -m "feat: task description"
git push origin main
```

### Never Commit
- `.env` files (contains secrets)
- `venv/` folder (virtual environment)
- `__pycache__/` directories
- `*.log` files
- `data/db/*.db` files (database files)

## Workflow Example
1. User asks: "Add configuration system"
2. You implement the feature
3. Code is complete
4. **You MUST run:** `python scripts/auto_commit.py "Added configuration system"`
5. Changes are automatically committed and pushed to GitHub
6. Task is complete

## Documentation & Progress Tracking (CRITICAL)

### After Completing Every Task
**CRITICAL RULE:** After completing ANY task, you MUST:
1. Update documentation: `python scripts/maintenance/update_docs.py "Task Name" TASK-ID complete`
2. Verify progress tracking files are updated:
   - `docs/progress/CHECKPOINT.md` - Quick resume point
   - `docs/progress/PROJECT_PROGRESS.md` - Detailed progress
   - `docs/architecture/CODE_DOCUMENTATION.md` - Code documentation (if new code added)

### Documentation File Management (CRITICAL)
**NEVER CREATE NEW MARKDOWN FILES UNLESS ABSOLUTELY NECESSARY**

**RULE:** Always append/update existing files instead of creating new ones:
- ✅ **APPEND** to existing documentation files
- ✅ **UPDATE** existing sections in files
- ✅ **CHECK** if similar information exists before creating
- ❌ **DO NOT** create new .md files for similar content
- ❌ **DO NOT** duplicate information across files

**Use these existing files:**
- Progress updates → `docs/progress/PROJECT_PROGRESS.md` (append to "Recent Changes Log")
- Code documentation → `docs/architecture/CODE_DOCUMENTATION.md` (append new sections)
- Architecture changes → `docs/architecture/ARCHITECTURE.md` (update sections)
- Setup notes → `docs/setup/` (update appropriate existing file)
- Git workflow → `docs/git/` (update appropriate existing file)
- Structure info → `docs/README.md` (update structure section)

**Only create new files if:**
- It's a completely new category that doesn't exist
- It's a new guide from `docs/guides/` folder
- It's a new hardware-specific documentation

**Before creating any .md file:**
1. Check if similar information exists in existing files
2. If yes, append/update that file instead
3. If no, confirm it's truly a new category before creating

### Resuming Work in New Chat
**When user says "go" or "continue":**
1. Read `docs/progress/CHECKPOINT.md` to find last completed task
2. Read `docs/progress/PROJECT_PROGRESS.md` for detailed status
3. Read `docs/guides/ZEMA-CURSOR-PROMPTS.md` for next prompt
4. Execute the next prompt automatically
5. Update all documentation files
6. Commit changes

### Documentation Files
- `docs/progress/CHECKPOINT.md` - Quick resume point (always check this first)
- `docs/progress/PROJECT_PROGRESS.md` - Master progress tracker
- `docs/architecture/CODE_DOCUMENTATION.md` - Detailed file-by-file documentation
- `docs/architecture/ARCHITECTURE.md` - System architecture documentation

## Auto-Documentation Rule (CRITICAL)

### When Creating New Python Files
**CRITICAL RULE:** Whenever a new Python file is created, you MUST:
1. Create corresponding documentation file in `docs/` folder mirroring the same structure
2. Documentation file path: `docs/{same_path_as_python_file}.md`
3. Example: `src/voice/audio_io.py` → `docs/src/voice/audio_io.md`

### Documentation Template
Each new Python file documentation MUST include:
- **File Location**: Path to the Python file
- **Purpose**: What the file does
- **Why It Was Created**: Context and reasoning
- **How It Works**: Detailed explanation of functionality
- **Dependencies**: Required libraries/modules
- **Usage**: How to use it with examples
- **Integration**: How it fits into the project

### Auto-Documentation Process
1. **Create Python file** in appropriate location
2. **Create documentation file** in `docs/` following same path structure
3. **Write comprehensive documentation** using the template above
4. **Update folder README.md** if the folder's purpose changes
5. **Verify documentation** matches the code structure

### Folder Documentation
When creating new folders:
- Create `docs/{folder_path}/README.md` explaining:
  - What the folder contains
  - Purpose of the folder
  - How files work together
  - Key concepts

### Documentation Checklist
After creating any Python file:
- [ ] Created corresponding `.md` file in `docs/` mirroring path structure
- [ ] Documentation includes all required sections (Purpose, Why Created, How It Works, etc.)
- [ ] Updated folder `README.md` if needed
- [ ] Documentation follows existing documentation style
- [ ] Code examples included where relevant

### Examples
**Creating `src/voice/wakeword.py`:**
1. Create `docs/src/voice/wakeword.md`
2. Include all required sections
3. Update `docs/src/voice/README.md` if needed

**Creating `scripts/maintenance/new_script.py`:**
1. Create `docs/scripts/maintenance/new_script.md`
2. Include all required sections
3. Update `docs/scripts/maintenance/README.md` if needed

### Auto-Documentation Helper Script
Use `scripts/maintenance/create_doc.py` to generate documentation template:
```bash
python scripts/maintenance/create_doc.py src/voice/wakeword.py
```
This will:
- Parse the Python file
- Extract classes, functions, imports
- Generate documentation template in `docs/src/voice/wakeword.md`
- Fill in TODO sections that need manual completion

## Compliance Checking & Documentation Updates (CRITICAL)

### After Completing Every Task
**CRITICAL RULE:** After completing ANY task, feature, or change, you MUST:

1. **Run compliance check:** `python scripts/maintenance/check_rules_compliance.py`
   - Verifies code follows all .cursorrules requirements
   - Checks for type hints, docstrings, project structure
   - Checks for NO EMOJIS in code (ASCII-compatible output only)
   - Checks UI-First Configuration compliance (settings in Dashboard)
   - Identifies any violations

2. **Fix any compliance issues** before proceeding

3. **Update documentation** using `scripts/maintenance/update_docs.py`:
   ```bash
   python scripts/maintenance/update_docs.py "Task Name" TASK-ID complete
   ```

4. **Verify documentation files are updated:**
   - `docs/progress/CHECKPOINT.md` - Quick resume point
   - `docs/progress/PROJECT_PROGRESS.md` - Detailed progress
   - `docs/architecture/CODE_DOCUMENTATION.md` - Code documentation (if new code added)
   - `docs/architecture/ARCHITECTURE.md` - Architecture changes (if architecture changed)

5. **Run auto-commit:** `python scripts/maintenance/auto_commit.py "task description"`

### Compliance Check Command
```bash
# Run compliance check
python scripts/maintenance/check_rules_compliance.py

# This checks:
# - Project structure (all required directories exist)
# - Python code style (type hints, docstrings)
# - Dependencies (requirements.txt)
# - Git workflow (auto_commit.py exists)
```

### Documentation Update Command
```bash
# Update documentation after task completion
python scripts/maintenance/update_docs.py "Task Name" TASK-ID complete

# Examples:
python scripts/maintenance/update_docs.py "SETUP-001" SETUP-001 complete
python scripts/maintenance/update_docs.py "Smart Hybrid Mode" ARCH-001 complete
```

### Complete Task Completion Workflow
When finishing any task, ALWAYS follow this sequence:

1. [ ] Code is complete and tested
2. [ ] Follows project style guidelines (including NO EMOJIS in code)
3. [ ] **Check UI-First Configuration**: If any new settings/config were added, ensure they're in Settings Dashboard
4. [ ] **Run compliance check:** `python scripts/maintenance/check_rules_compliance.py`
5. [ ] Fix any compliance violations found
6. [ ] **Update documentation:** `python scripts/maintenance/update_docs.py "Task Name" TASK-ID complete`
7. [ ] Verify documentation files updated (CHECKPOINT.md, PROJECT_PROGRESS.md, etc.)
8. [ ] **Update verification checkboxes in ZEMA-CURSOR-PROMPTS.md** (change `- [ ]` to `- [x]`)
9. [ ] **Run auto-commit:** `python scripts/maintenance/auto_commit.py "task description"`
10. [ ] Verify push to GitHub was successful
11. [ ] **Display verification checklist** showing all completed items in your response

**CRITICAL: Final Step - Display Verification Checklist**
After completing any task, you MUST display the verification checklist in your completion response showing:
- Task name and status (✅ COMPLETE)
- All verification items marked as complete
- Completion date
- Summary of what was accomplished

This helps the user see exactly what was verified and completed.

### Why This Matters
- **Compliance checks** ensure code quality and consistency
- **Documentation updates** keep progress tracking accurate
- **Verification checkboxes** keep prompt file synchronized with actual progress
- **Display verification checklist** provides clear completion summary to user
- **Auto-commit** ensures changes are saved to GitHub
- All steps together maintain project integrity

### Example Complete Workflow
```bash
# 1. Complete task (e.g., update architecture)
# ... make changes ...

# 2. Run compliance check
python scripts/maintenance/check_rules_compliance.py

# 3. Fix any issues found

# 4. Update documentation
python scripts/maintenance/update_docs.py "Smart Hybrid Mode Architecture" ARCH-001 complete

# 5. Commit and push
python scripts/maintenance/auto_commit.py "Updated architecture for Smart Hybrid Mode"
```

This ensures every task completion:
- ✅ Code is compliant with rules
- ✅ Documentation is up-to-date
- ✅ Changes are committed to GitHub

## Task Verification Checklist (CRITICAL)

### Verification Process
**CRITICAL RULE:** After completing ANY task, you MUST verify all checklist items from the task's verification section and mark them as complete in this checklist.

### How to Use This Checklist
1. When a task is completed, find its verification section in `docs/guides/ZEMA-CURSOR-PROMPTS.md`
2. Complete all verification items listed
3. Mark the task as complete below with ✅ and date
4. Update this checklist whenever you complete a task

### Phase 0: Project Setup

#### SETUP-001: Create Project Structure ✅ COMPLETE
**Completed:** 2025-11-02  
**Verification Items:**
- ✅ All directories created
- ✅ All __init__.py files exist
- ✅ README.md created
- ✅ requirements.txt created with all dependencies
- ✅ .gitignore created
- ✅ .env.example created
- ✅ pyproject.toml created
- ✅ Structure verified
- ✅ Committed: `python scripts/auto_commit.py "SETUP-001 - Create project structure"`

#### SETUP-002: Configuration System ✅ COMPLETE
**Completed:** 2025-11-03  
**Verification Items:**
- ✅ Settings class created with all fields
- ✅ Validation works for all fields
- ✅ .env.example has all variables
- ✅ Settings load from .env correctly
- ✅ Default values work
- ✅ Type conversion works
- ✅ Committed: `python scripts/auto_commit.py "SETUP-002 - Configuration system"`

#### SETUP-003: Logging System ✅ COMPLETE
**Completed:** 2025-11-03  
**Verification Items:**
- ✅ Logging setup function created
- ✅ Console handler works (colored output)
- ✅ File handler works (JSON format)
- ✅ Performance decorator works for async/sync
- ✅ Log rotation works
- ✅ All log levels work
- ✅ Committed: `python scripts/auto_commit.py "SETUP-003 - Logging system"`

### Notes
- Only mark tasks as complete (✅) after ALL verification items are checked
- Always include the completion date
- Update this checklist immediately after completing a task
- Reference the verification section in `docs/guides/ZEMA-CURSOR-PROMPTS.md` for each task's specific requirements

### CRITICAL: Update Verification Checkboxes in ZEMA-CURSOR-PROMPTS.md
**CRITICAL RULE:** After completing ANY task, you MUST also update the verification checkboxes in `docs/guides/ZEMA-CURSOR-PROMPTS.md`:
1. Find the task's verification section in `docs/guides/ZEMA-CURSOR-PROMPTS.md`
2. Change all `- [ ]` checkboxes to `- [x]` for completed items
3. This ensures the prompt file reflects actual completion status
4. Both `.cursorrules` checklist AND `ZEMA-CURSOR-PROMPTS.md` verification must be updated

**Example:**
Before (in ZEMA-CURSOR-PROMPTS.md):
```
**Verification:**
- [ ] Settings class created with all fields
- [ ] Validation works for all fields
```

After (when completed):
```
**Verification:**
- [x] Settings class created with all fields
- [x] Validation works for all fields
```